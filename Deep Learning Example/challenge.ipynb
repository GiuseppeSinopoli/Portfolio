{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "from torch.autograd import Variable\r\n",
    "\r\n",
    "import torchvision\r\n",
    "import torchvision.transforms as transforms\r\n",
    "from torch.utils.data import Dataset, DataLoader\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def output_label(label):\r\n",
    "    output_mapping = {\r\n",
    "                 0: \"T-shirt/Top\",\r\n",
    "                 1: \"Trouser\",\r\n",
    "                 2: \"Pullover\",\r\n",
    "                 3: \"Dress\",\r\n",
    "                 4: \"Coat\", \r\n",
    "                 5: \"Sandal\", \r\n",
    "                 6: \"Shirt\",\r\n",
    "                 7: \"Sneaker\",\r\n",
    "                 8: \"Bag\",\r\n",
    "                 9: \"Ankle Boot\"\r\n",
    "                 }\r\n",
    "    input = (label.item() if type(label) == torch.Tensor else label)\r\n",
    "    return output_mapping[input]\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(\"./data\", download=True, transform=\r\n",
    "                                                transforms.Compose([transforms.ToTensor()]))\r\n",
    "test_set = torchvision.datasets.FashionMNIST(\"./data\", download=True, train=False, transform=\r\n",
    "                                               transforms.Compose([transforms.ToTensor()])) \r\n",
    "\r\n",
    "train_loader = torch.utils.data.DataLoader(train_set, \r\n",
    "                                           batch_size=100)\r\n",
    "test_loader = torch.utils.data.DataLoader(test_set,\r\n",
    "                                          batch_size=100)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "1.1%"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100.6%"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "6.8%"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "119.3%"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "C:\\Users\\151461\\anaconda3\\envs\\Torch\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "\r\n",
    "class FashionCNN(nn.Module):\r\n",
    "    \r\n",
    "    def __init__(self):\r\n",
    "        super(FashionCNN, self).__init__()\r\n",
    "        \r\n",
    "        self.layer1 = nn.Sequential(\r\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\r\n",
    "            nn.BatchNorm2d(32),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\r\n",
    "        )\r\n",
    "        \r\n",
    "        self.layer2 = nn.Sequential(\r\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\r\n",
    "            nn.BatchNorm2d(64),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.MaxPool2d(2)\r\n",
    "        )\r\n",
    "        \r\n",
    "        self.fc1 = nn.Linear(in_features=64*6*6, out_features=600)\r\n",
    "        self.drop = nn.Dropout2d(0.25)\r\n",
    "        self.fc2 = nn.Linear(in_features=600, out_features=120)\r\n",
    "        self.fc3 = nn.Linear(in_features=120, out_features=10)\r\n",
    "        \r\n",
    "    def forward(self, x):\r\n",
    "        out = self.layer1(x)\r\n",
    "        out = self.layer2(out)\r\n",
    "        out = out.view(out.size(0), -1)\r\n",
    "        out = self.fc1(out)\r\n",
    "        out = self.drop(out)\r\n",
    "        out = self.fc2(out)\r\n",
    "        out = self.fc3(out)\r\n",
    "        \r\n",
    "        return out\r\n",
    "    \r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "model = FashionCNN()\r\n",
    "model.to(device)\r\n",
    "\r\n",
    "error = nn.CrossEntropyLoss()\r\n",
    "\r\n",
    "learning_rate = 0.003\r\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\r\n",
    "print(model)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "FashionCNN(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Linear(in_features=2304, out_features=600, bias=True)\n",
      "  (drop): Dropout2d(p=0.25, inplace=False)\n",
      "  (fc2): Linear(in_features=600, out_features=120, bias=True)\n",
      "  (fc3): Linear(in_features=120, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "num_epochs = 5\r\n",
    "count = 0\r\n",
    "\r\n",
    "loss_list = []\r\n",
    "iteration_list = []\r\n",
    "accuracy_list = []\r\n",
    "\r\n",
    "\r\n",
    "predictions_list = []\r\n",
    "labels_list = []\r\n",
    "\r\n",
    "for epoch in range(num_epochs):\r\n",
    "    for images, labels in train_loader:\r\n",
    "        images, labels = images.to(device), labels.to(device)\r\n",
    "        train = Variable(images.view(100, 1, 28, 28))\r\n",
    "        labels = Variable(labels)\r\n",
    "        outputs = model(train)\r\n",
    "        loss = error(outputs, labels)\r\n",
    "        optimizer.zero_grad()\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "        count += 1\r\n",
    "        if not (count % 50):  \r\n",
    "            total = 0\r\n",
    "            correct = 0\r\n",
    "        \r\n",
    "            for images, labels in test_loader:\r\n",
    "                images, labels = images.to(device), labels.to(device)\r\n",
    "                labels_list.append(labels)\r\n",
    "                test = Variable(images.view(100, 1, 28, 28))\r\n",
    "            \r\n",
    "                outputs = model(test)\r\n",
    "            \r\n",
    "                predictions = torch.max(outputs, 1)[1].to(device)\r\n",
    "                predictions_list.append(predictions)\r\n",
    "                correct += (predictions == labels).sum()\r\n",
    "            \r\n",
    "                total += len(labels)\r\n",
    "            \r\n",
    "            accuracy = correct * 100 / total\r\n",
    "            loss_list.append(loss.data)\r\n",
    "            iteration_list.append(count)\r\n",
    "            accuracy_list.append(accuracy)\r\n",
    "        \r\n",
    "        if not (count % 500):\r\n",
    "            print(\"Iteration: {}, Loss: {}, Accuracy: {}%\".format(count, loss.data, accuracy))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Iteration: 500, Loss: 0.4577225148677826, Accuracy: 87.12999725341797%\n",
      "Iteration: 1000, Loss: 0.358108252286911, Accuracy: 86.19999694824219%\n",
      "Iteration: 1500, Loss: 0.30460765957832336, Accuracy: 87.54999542236328%\n",
      "Iteration: 2000, Loss: 0.2996406853199005, Accuracy: 89.2699966430664%\n",
      "Iteration: 2500, Loss: 0.1319340467453003, Accuracy: 89.18999481201172%\n",
      "Iteration: 3000, Loss: 0.17762885987758636, Accuracy: 89.38999938964844%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "class_correct = [0. for _ in range(10)]\r\n",
    "total_correct = [0. for _ in range(10)]\r\n",
    "\r\n",
    "with torch.no_grad():\r\n",
    "    for images, labels in test_loader:\r\n",
    "        images, labels = images.to(device), labels.to(device)\r\n",
    "        test = Variable(images)\r\n",
    "        outputs = model(test)\r\n",
    "        predicted = torch.max(outputs, 1)[1]\r\n",
    "        c = (predicted == labels).squeeze()\r\n",
    "        \r\n",
    "        for i in range(100):\r\n",
    "            label = labels[i]\r\n",
    "            class_correct[label] += c[i].item()\r\n",
    "            total_correct[label] += 1\r\n",
    "        \r\n",
    "for i in range(10):\r\n",
    "    print(\"Accuracy of {}: {:.2f}%\".format(output_label(i), class_correct[i] * 100 / total_correct[i]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy of T-shirt/Top: 84.10%\n",
      "Accuracy of Trouser: 98.50%\n",
      "Accuracy of Pullover: 69.30%\n",
      "Accuracy of Dress: 92.40%\n",
      "Accuracy of Coat: 87.00%\n",
      "Accuracy of Sandal: 94.70%\n",
      "Accuracy of Shirt: 76.30%\n",
      "Accuracy of Sneaker: 97.90%\n",
      "Accuracy of Bag: 98.60%\n",
      "Accuracy of Ankle Boot: 95.70%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('Torch': conda)"
  },
  "interpreter": {
   "hash": "64e73729ec4eaa0a1cfe55efd54f3cbca0f1d0d7816917a48a62b8b078c8851f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}